{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7e6f2f",
   "metadata": {},
   "source": [
    "# Exploiter le guide des recettes\n",
    "Dans cet exercice, nous introduisons le Retrieval Augmented Generation (RAG), une approche qui permet à un agent basé sur un LLM de s’appuyer sur des données externes pour générer des réponses plus fiables, précises et à jour. Plutôt que de se reposer uniquement sur les connaissances internes du modèle, le LLM va d’abord rechercher des informations pertinentes dans une base de documents, puis utiliser ces informations comme contexte pour produire sa réponse.\n",
    "\n",
    "Le RAG est particulièrement utile lorsque l’on travaille avec des documents spécifiques (documentation, articles, données métier) ou lorsque l’on souhaite éviter les hallucinations. Dans cet exercice, nous allons combiner DSPy pour l’orchestration du raisonnement et Qdrant comme base de données vectorielle pour la recherche sémantique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23d0d10",
   "metadata": {},
   "source": [
    "## Définition des variables\n",
    "Les variables sont lues depuis le fichier [.env](../../.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\"../../.env\")\n",
    "\n",
    "llm_model = config.get('LLM_MODEL')\n",
    "api_key = config.get('LLM_API_KEY')\n",
    "# Uncomment for local api call\n",
    "# api_base = config.get('LLM_API_URL')\n",
    "\n",
    "\n",
    "qdrant_url = config.get('QDRANT_URL')\n",
    "qdrant_api_key = config.get('QDRANT_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68428de9",
   "metadata": {},
   "source": [
    "## Configuration du llm sur dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f258dc-c051-47ad-a0c6-fe3d1d64396e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy_qdrant import QdrantRM\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Ton vectorizer (embedding) francophone\n",
    "hf_embed = HuggingFaceEmbeddings(\n",
    "    model_name=\"manu/bge-fr-en\",  # modèle francophone + multilingue\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "def vectorizer(text_or_texts):\n",
    "    if isinstance(text_or_texts, list):\n",
    "        return hf_embed.embed_documents(text_or_texts)\n",
    "    else:\n",
    "        return hf_embed.embed_query(text_or_texts)\n",
    "\n",
    "\n",
    "lm = dspy.LM(llm_model, api_key=api_key)\n",
    "# Uncomment for local api call\n",
    "#lm = dspy.LM(llm_model, api_base=api_base, track_usage=True, temperature=1.5, max_tokens=1024)\n",
    "\n",
    "client = QdrantClient(qdrant_url, api_key=qdrant_api_key)\n",
    "rm = QdrantRM(\n",
    "    qdrant_collection_name=\"livre-recette\", \n",
    "    qdrant_client=client,\n",
    "    vector_name=\"recette\",\n",
    "    document_field=\"text\",\n",
    "    vectorizer=vectorizer\n",
    ")\n",
    "\n",
    "\n",
    "dspy.configure_cache(\n",
    "    enable_disk_cache=False,\n",
    "    enable_memory_cache=False,\n",
    ")\n",
    "dspy.configure(lm=lm, rm=rm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ca7e8",
   "metadata": {},
   "source": [
    "## Créer le Retriever\n",
    "\n",
    "Cette section définit la fonction `retriever` qui permet de rechercher les passages pertinents dans la base de données vectorielle. Elle utilise l'objet `dspy.Retrieve` pour effectuer une recherche sémantique basée sur la requête utilisateur et retourne un certain nombre de résultats (défini par le paramètre `k`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def retriever(query: str, k: int) -> list[str]:\n",
    "    retriever = dspy.Retrieve(k=k)\n",
    "    revelant_passages = retriever(query).passages\n",
    "    print(f\"Revelant passages: {revelant_passages}\")\n",
    "    return revelant_passages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46948c6f",
   "metadata": {},
   "source": [
    "## Enrichir la génération\n",
    "\n",
    "Cette section définit l'assistant qui utilise le raisonnement en chaîne (Chain of Thought) pour enrichir la réponse finale avec le contexte récupéré. Elle combine les passages pertinents de la base de données avec la question utilisateur dans un format spécifique pour produire une réponse plus précise et fondée sur des sources externes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assistant = dspy.ChainOfThought(\"context, question -> response\")\n",
    "\n",
    "def rag(query: str, k: int) -> list[str]:\n",
    "    revelant_passages = retriever(query, k)\n",
    "    return assistant(context=revelant_passages, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bda616",
   "metadata": {},
   "source": [
    "## Exécuter le RAG\n",
    "\n",
    "Cette section montre comment exécuter le système RAG complet. Elle appelle la fonction `rag` avec une requête utilisateur spécifique et un nombre de passages à récupérer (k=2). Le résultat est affiché à l'aide de la bibliothèque rich, permettant d'obtenir une sortie formatée et l'historique des appels du modèle pour analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d51541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "results = rag(query=\"Comment cuisiner un nachos garnis ?\", k=2)\n",
    "\n",
    "print(results)\n",
    "print(lm.history)\n",
    "dspy.inspect_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kata-ai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
