{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7e6f2f",
   "metadata": {},
   "source": [
    "# 04- Structurer la sortie des LLMs\n",
    "Dans cet exercice, nous allons nous concentrer sur la structuration des réponses des modèles de langage. Jusqu’ici, nous avons vu comment interagir avec un LLM, utiliser des prompts simples et introduire le raisonnement étape par étape avec les Chain of Thought. Cependant, les modèles renvoient souvent des réponses sous forme de texte libre, ce qui peut être difficile à exploiter de manière fiable dans une application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23d0d10",
   "metadata": {},
   "source": [
    "## Définition des variables\n",
    "Les variables sont lues depuis le fichier [.env](../../.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\"../../.env\")\n",
    "\n",
    "llm_model = config.get('LLM_MODEL')\n",
    "api_key = config.get('LLM_API_KEY')\n",
    "# Uncomment for local api call\n",
    "# api_base = config.get('LLM_API_URL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68428de9",
   "metadata": {},
   "source": [
    "## Configuration du llm sur dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f258dc-c051-47ad-a0c6-fe3d1d64396e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "lm = dspy.LM(llm_model, api_key=api_key)\n",
    "# Uncomment for local api call\n",
    "#lm = dspy.LM(llm_model, api_base=api_base, track_usage=True, temperature=1.5, max_tokens=1024)\n",
    "\n",
    "dspy.configure_cache(\n",
    "    enable_disk_cache=False,\n",
    "    enable_memory_cache=False,\n",
    ")\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f72ee",
   "metadata": {},
   "source": [
    "En réalité, l’utilisation classique question -> answer n’est qu’un alias simplifié pour créer une interaction avec un LLM : derrière ce raccourci, il est possible de définir des signatures plus complètes basées sur des classes Python. Cela signifie que vous pouvez structurer vos prompts, vos entrées et vos sorties en utilisant des classes qui décrivent explicitement les types et les champs attendus, plutôt que de vous limiter à un texte libre. Cette approche rend vos appels plus robustes, plus lisibles et plus facilement exploitables par votre code, tout en conservant la flexibilité de générer des réponses riches depuis le modèle de langage.\n",
    "\n",
    "<ins>**Exercice:**</ins> Modifier la signature et l'exécution pour extraire à partir du contenu de l'article `article_content` une liste de plat avec pour chacun le nom, la difficulté(Débutant, Intermédiaire ou Avancé), le temps de préparation et le temps de cuisson\n",
    "\n",
    "##  Lecture de l'article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174261db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(\"../../utils\").resolve()))\n",
    "from file_reader import read_file\n",
    "\n",
    "article_content = read_file(\"../../assets/articles/002-article.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ca7e8",
   "metadata": {},
   "source": [
    "## Créer une signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ExpertCulinaire(dspy.Signature):\n",
    "    question: str = dspy.InputField(desc=\"Question posée\")\n",
    "    reponse: str = dspy.OutputField(desc=\"Réponse à la question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bda616",
   "metadata": {},
   "source": [
    "## Exécuter la prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d51541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "\n",
    "assistant = dspy.Predict(ExpertCulinaire)\n",
    "response = assistant(question=\"Combien de planètes dans le système solaire ?\")\n",
    "\n",
    "print(response.reponse)\n",
    "dspy.inspect_history()\n",
    "print(lm.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kata-ai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
